{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepBind_colab_finale.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whtns/todo/blob/main/Binding_sites_Prediction_PyTorch_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c672ffeb",
        "outputId": "4eb4996e-ed73-4ad0-fa48-2363253b03f3"
      },
      "source": [
        "# !uv pip install wheel.pep425tags"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "\u001b[2K  \u001b[31m×\u001b[0m No solution found when resolving dependencies:\n",
            "\u001b[31m  ╰─▶ \u001b[0mBecause wheel-pep425tags was not found in the package registry and you\n",
            "\u001b[31m      \u001b[0mrequire wheel-pep425tags, we can conclude that your requirements are\n",
            "\u001b[31m      \u001b[0munsatisfiable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db5a9cd9",
        "outputId": "ee024689-7e42-4908-bdf0-714a2d226a00"
      },
      "source": [
        "!uv pip install wheel"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 390ms\u001b[0m\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d57e7be",
        "outputId": "40ee631b-a5c7-4e79-8bbe-37f9cdcc6a52"
      },
      "source": [
        "!uv pip install torch torchvision"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m26 packages\u001b[0m \u001b[2min 272ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m10 packages\u001b[0m \u001b[2min 18.53s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m10 packages\u001b[0m \u001b[2min 109ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m10 packages\u001b[0m \u001b[2min 15ms\u001b[0m\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.5.3.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.4.5.8\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.3.0.75\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.1.0.70\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.3.61\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.1.3\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.6.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.5.147\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.3.83\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.1.9\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.1.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.3.1.170\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "T_Goiz940CV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dcb68e1-da02-4653-f8c9-2a982a921c67"
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "# from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "# platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "# !uv pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "aeIU5kFp0H1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0477bf1-796f-436a-b74d-9c0d48541c85"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to download the data from the original [publication](https://static-content.springer.com/esm/art%3A10.1038%2Fnbt.3300/MediaObjects/41587_2015_BFnbt3300_MOESM62_ESM.zip)"
      ],
      "metadata": {
        "id": "oZkxbeb02P9U"
      }
    },
    {
      "metadata": {
        "id": "O_pH6Jdz0VhA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b669d59-78cc-4339-97ff-4351981ca809"
      },
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/Deepbind/\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "code  data  README.TXT\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "hJ3u9Tweh2jw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d5f15f-2db5-467d-804e-de7367ba8c49"
      },
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!uv pip install gputil\n",
        "!uv pip install psutil\n",
        "!uv pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "       process = psutil.Process(os.getpid())\n",
        "       print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "       print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 1.12s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 960ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgputil\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 138ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 159ms\u001b[0m\u001b[0m\n",
            "Gen RAM Free: 9.7 GB  | Proc size: 471.6 MB\n",
            "GPU RAM Free: 15092MB | Used: 2MB | Util   0% | Total 15360MB\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "lHI_wW1cz8FN"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import math\n",
        "import random\n",
        "import gzip\n",
        "from scipy.stats import bernoulli\n",
        "import torch\n",
        "from sklearn import metrics"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9mOZziHBz8FT"
      },
      "cell_type": "code",
      "source": [
        "nummotif=16 #number of motifs to discover\n",
        "bases='ACGT' #DNA bases\n",
        "basesRNA='ACGU'#RNA bases\n",
        "batch_size=64 #fixed batch size -> see notes to problem about it\n",
        "dictReverse={'A':'T','C':'G','G':'C','T':'A','N':'N'} #dictionary to implement reverse-complement mode\n",
        "reverse_mode=False"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DJn4P52Fz8FX"
      },
      "cell_type": "code",
      "source": [
        "def seqtopad(sequence,motlen,kind='DNA'):\n",
        "    rows=len(sequence)+2*motlen-2\n",
        "    S=np.empty([rows,4])\n",
        "    base= bases if kind=='DNA' else basesRNA\n",
        "    for i in range(rows):\n",
        "        for j in range(4):\n",
        "            if i-motlen+1<len(sequence) and sequence[i-motlen+1]=='N' or i<motlen-1 or i>len(sequence)+motlen-2:\n",
        "                S[i,j]=np.float32(0.25)\n",
        "            elif sequence[i-motlen+1]==base[j]:\n",
        "                S[i,j]=np.float32(1)\n",
        "            else:\n",
        "                S[i,j]=np.float32(0)\n",
        "    return np.transpose(S)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lBcVVpC8z8Fb"
      },
      "cell_type": "code",
      "source": [
        "def dinucshuffle(sequence):\n",
        "    b=[sequence[i:i+2] for i in range(0, len(sequence), 2)]\n",
        "    random.shuffle(b)\n",
        "    d=''.join([str(x) for x in b])\n",
        "    return d"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LGWkcTgD7xrE"
      },
      "cell_type": "code",
      "source": [
        "def complement(seq):\n",
        "    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N': 'N'}\n",
        "    complseq = [complement[base] for base in seq]\n",
        "    return complseq\n",
        "\n",
        "def reverse_complement(seq):\n",
        "    seq = list(seq)\n",
        "    seq.reverse()\n",
        "    return ''.join(complement(seq))\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O7LnslLYz8Fj"
      },
      "cell_type": "code",
      "source": [
        "class Chip():\n",
        "    def __init__(self,filename,motiflen=24,reverse_complemet_mode=reverse_mode):\n",
        "        self.file = filename\n",
        "        self.motiflen = motiflen\n",
        "        self.reverse_complemet_mode=reverse_complemet_mode\n",
        "\n",
        "    def openFile(self):\n",
        "        train_dataset=[]\n",
        "        with gzip.open(self.file, 'rt') as data:\n",
        "            next(data)\n",
        "            reader = csv.reader(data,delimiter='\\t')\n",
        "            if not self.reverse_complemet_mode:\n",
        "              for row in reader:\n",
        "                      train_dataset.append([seqtopad(row[2],self.motiflen),[1]])\n",
        "                      train_dataset.append([seqtopad(dinucshuffle(row[2]),self.motiflen),[0]])\n",
        "            else:\n",
        "              for row in reader:\n",
        "                      train_dataset.append([seqtopad(row[2],self.motiflen),[1]])\n",
        "                      train_dataset.append([seqtopad(reverse_complement(row[2]),self.motiflen),[1]])\n",
        "                      train_dataset.append([seqtopad(dinucshuffle(row[2]),self.motiflen),[0]])\n",
        "                      train_dataset.append([seqtopad(dinucshuffle(reverse_complement(row[2])),self.motiflen),[0]])\n",
        "        #random.shuffle(train_dataset)\n",
        "        train_dataset_pad=train_dataset\n",
        "\n",
        "        size=int(len(train_dataset_pad)/3)\n",
        "        firstvalid=train_dataset_pad[:size]\n",
        "        secondvalid=train_dataset_pad[size:size+size]\n",
        "        thirdvalid=train_dataset_pad[size+size:]\n",
        "        firsttrain=secondvalid+thirdvalid\n",
        "        secondtrain=firstvalid+thirdvalid\n",
        "        thirdtrain=firstvalid+secondvalid\n",
        "        return firsttrain,firstvalid,secondtrain,secondvalid,thirdtrain,thirdvalid,train_dataset_pad"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GwYhmKt6z8Fn"
      },
      "cell_type": "code",
      "source": [
        "# chipseq=Chip('/content/drive/My Drive/Deepbind/ZBTB7A_HepG2_ZBTB7A_(SC-34508)_HudsonAlpha_AC.seq.gz')\n",
        "chipseq=Chip('/content/drive/My Drive/Deepbind/data/encode/ELK1_GM12878_ELK1_(1277-1)_Stanford_AC.seq.gz')\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Bn0w6urz8Fs"
      },
      "cell_type": "code",
      "source": [
        "train1,valid1,train2,valid2,train3,valid3,alldataset=chipseq.openFile()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pX3Kgiaoz8Fw"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class chipseq_dataset(Dataset):\n",
        "    \"\"\" Diabetes dataset.\"\"\"\n",
        "\n",
        "    def __init__(self,xy=None):\n",
        "        self.x_data=np.asarray([el[0] for el in xy],dtype=np.float32)\n",
        "        self.y_data =np.asarray([el[1] for el in xy ],dtype=np.float32)\n",
        "        self.x_data = torch.from_numpy(self.x_data)\n",
        "        self.y_data = torch.from_numpy(self.y_data)\n",
        "        self.len=len(self.x_data)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yD_F4vtcz8F2"
      },
      "cell_type": "code",
      "source": [
        "train1_dataset=chipseq_dataset(train1)\n",
        "train2_dataset=chipseq_dataset(train2)\n",
        "train3_dataset=chipseq_dataset(train3)\n",
        "valid1_dataset=chipseq_dataset(valid1)\n",
        "valid2_dataset=chipseq_dataset(valid2)\n",
        "valid3_dataset=chipseq_dataset(valid3)\n",
        "alldataset_dataset=chipseq_dataset(alldataset)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RfxIcGZoz8F9"
      },
      "cell_type": "code",
      "source": [
        "batchSize=64\n",
        "if reverse_mode:\n",
        "  train_loader1 = DataLoader(dataset=train1_dataset,batch_size=batchSize,shuffle=False)\n",
        "  train_loader2 = DataLoader(dataset=train2_dataset,batch_size=batchSize,shuffle=False)\n",
        "  train_loader3 = DataLoader(dataset=train3_dataset,batch_size=batchSize,shuffle=False)\n",
        "  valid1_loader = DataLoader(dataset=valid1_dataset,batch_size=batchSize,shuffle=False)\n",
        "  valid2_loader = DataLoader(dataset=valid2_dataset,batch_size=batchSize,shuffle=False)\n",
        "  valid3_loader = DataLoader(dataset=valid3_dataset,batch_size=batchSize,shuffle=False)\n",
        "  alldataset_loader=DataLoader(dataset=alldataset_dataset,batch_size=batchSize,shuffle=False)\n",
        "else:\n",
        "  train_loader1 = DataLoader(dataset=train1_dataset,batch_size=batchSize,shuffle=True)\n",
        "  train_loader2 = DataLoader(dataset=train2_dataset,batch_size=batchSize,shuffle=True)\n",
        "  train_loader3 = DataLoader(dataset=train3_dataset,batch_size=batchSize,shuffle=True)\n",
        "  valid1_loader = DataLoader(dataset=valid1_dataset,batch_size=batchSize,shuffle=False)\n",
        "  valid2_loader = DataLoader(dataset=valid2_dataset,batch_size=batchSize,shuffle=False)\n",
        "  valid3_loader = DataLoader(dataset=valid3_dataset,batch_size=batchSize,shuffle=False)\n",
        "  alldataset_loader=DataLoader(dataset=alldataset_dataset,batch_size=batchSize,shuffle=False)\n",
        "\n",
        "train_dataloader=[train_loader1,train_loader2,train_loader3]\n",
        "valid_dataloader=[valid1_loader,valid2_loader,valid3_loader]\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oHms3Olpz8GA"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "import torch.nn.functional as F\n",
        "# Hyper parameters\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "def logsampler(a,b):\n",
        "        x=np.random.uniform(low=0,high=1)\n",
        "        y=10**((math.log10(b)-math.log10(a))*x + math.log10(a))\n",
        "        return y\n",
        "\n",
        "def sqrtsampler(a,b):\n",
        "\n",
        "        x=np.random.uniform(low=0,high=1)\n",
        "        y=(b-a)*math.sqrt(x)+a\n",
        "        return y\n",
        "\n",
        "# input of shape(batch_size,inp_chan,iW)\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, nummotif,motiflen,poolType,neuType,mode,dropprob,learning_rate,momentum_rate,sigmaConv,sigmaNeu,beta1,beta2,beta3,reverse_complemet_mode=reverse_mode):\n",
        "\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.poolType=poolType\n",
        "        self.neuType=neuType\n",
        "        self.mode=mode\n",
        "        self.reverse_complemet_mode=reverse_complemet_mode\n",
        "        self.dropprob=dropprob\n",
        "        self.learning_rate=learning_rate\n",
        "        self.momentum_rate=momentum_rate\n",
        "        self.sigmaConv=sigmaConv\n",
        "        self.sigmaNeu=sigmaNeu\n",
        "        self.beta1=beta1\n",
        "        self.beta2=beta2\n",
        "        self.beta3=beta3\n",
        "        self.wConv=torch.randn(nummotif,4,motiflen).to(device)\n",
        "        torch.nn.init.normal_(self.wConv,mean=0,std=self.sigmaConv)\n",
        "        self.wConv.requires_grad=True\n",
        "\n",
        "\n",
        "        self.wRect=torch.randn(nummotif).to(device)\n",
        "        torch.nn.init.normal_(self.wRect)\n",
        "        self.wRect=-self.wRect\n",
        "        self.wRect.requires_grad=True\n",
        "\n",
        "\n",
        "        if neuType=='nohidden':\n",
        "\n",
        "            if poolType=='maxavg':\n",
        "                self.wNeu=torch.randn(2*nummotif,1).to(device)\n",
        "            else:\n",
        "                self.wNeu=torch.randn(nummotif,1).to(device)\n",
        "            self.wNeuBias=torch.randn(1).to(device)\n",
        "            torch.nn.init.normal_(self.wNeu,mean=0,std=self.sigmaNeu)\n",
        "            torch.nn.init.normal_(self.wNeuBias,mean=0,std=self.sigmaNeu)\n",
        "\n",
        "        else:\n",
        "            if poolType=='maxavg':\n",
        "                self.wHidden=torch.randn(2*nummotif,32).to(device)\n",
        "            else:\n",
        "\n",
        "                self.wHidden=torch.randn(nummotif,32).to(device)\n",
        "            self.wNeu=torch.randn(32,1).to(device)\n",
        "            self.wNeuBias=torch.randn(1).to(device)\n",
        "            self.wHiddenBias=torch.randn(32).to(device)\n",
        "            torch.nn.init.normal_(self.wNeu,mean=0,std=self.sigmaNeu)\n",
        "            torch.nn.init.normal_(self.wNeuBias,mean=0,std=self.sigmaNeu)\n",
        "            torch.nn.init.normal_(self.wHidden,mean=0,std=0.3)\n",
        "            torch.nn.init.normal_(self.wHiddenBias,mean=0,std=0.3)\n",
        "\n",
        "\n",
        "            self.wHidden.requires_grad=True\n",
        "            self.wHiddenBias.requires_grad=True\n",
        "            #wHiddenBias=tf.Variable(tf.truncated_normal([32,1],mean=0,stddev=sigmaNeu)) #hidden bias for everything\n",
        "\n",
        "        self.wNeu.requires_grad=True\n",
        "        self.wNeuBias.requires_grad=True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def divide_two_tensors(self,x):\n",
        "        l=torch.unbind(x)\n",
        "\n",
        "        list1=[l[2*i] for i in range(int(x.shape[0]/2))]\n",
        "        list2=[l[2*i+1] for i in range(int(x.shape[0]/2))]\n",
        "        x1=torch.stack(list1,0)\n",
        "        x2=torch.stack(list2,0)\n",
        "        return x1,x2\n",
        "    def forward_pass(self,x,mask=None,use_mask=False):\n",
        "\n",
        "        conv=F.conv1d(x, self.wConv, bias=self.wRect, stride=1, padding=0)\n",
        "        rect=conv.clamp(min=0)\n",
        "        maxPool, _ = torch.max(rect, dim=2)\n",
        "        if self.poolType=='maxavg':\n",
        "            avgPool= torch.mean(rect, dim=2)\n",
        "            pool=torch.cat((maxPool, avgPool), 1)\n",
        "        else:\n",
        "            pool=maxPool\n",
        "        if(self.neuType=='nohidden'):\n",
        "            if self.mode=='training':\n",
        "                if  not use_mask:\n",
        "                  mask=bernoulli.rvs(self.dropprob, size=len(pool[0]))\n",
        "                  mask=torch.from_numpy(mask).float().to(device)\n",
        "                pooldrop=pool*mask\n",
        "                out=pooldrop @ self.wNeu\n",
        "                out.add_(self.wNeuBias)\n",
        "            else:\n",
        "                out=self.dropprob*(pool @ self.wNeu)\n",
        "                out.add_(self.wNeuBias)\n",
        "        else:\n",
        "            hid=pool @ self.wHidden\n",
        "            hid.add_(self.wHiddenBias)\n",
        "            hid=hid.clamp(min=0)\n",
        "            if self.mode=='training':\n",
        "                if  not use_mask:\n",
        "                  mask=bernoulli.rvs(self.dropprob, size=len(hid[0]))\n",
        "                  mask=torch.from_numpy(mask).float().to(device)\n",
        "                hiddrop=hid*mask\n",
        "                out=self.dropprob*(hid @ self.wNeu)\n",
        "                out.add_(self.wNeuBias)\n",
        "            else:\n",
        "                out=self.dropprob*(hid @ self.wNeu)\n",
        "                out.add_(self.wNeuBias)\n",
        "        return out,mask\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if not  self.reverse_complemet_mode:\n",
        "            out,_=self.forward_pass(x)\n",
        "\n",
        "        else:\n",
        "\n",
        "            x1,x2=self.divide_two_tensors(x)\n",
        "            out1,mask=self.forward_pass(x1)\n",
        "            out2,_=self.forward_pass(x2,mask,True)\n",
        "            out=torch.max(out1, out2)\n",
        "\n",
        "        return out\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3_ACNZE2z8GE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f149141f-3506-405b-f4c5-d28fe640456f"
      },
      "cell_type": "code",
      "source": [
        "best_AUC=0\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "# device='cpu'\n",
        "learning_steps_list=[4000,8000,12000,16000,20000]\n",
        "for number in range(5):\n",
        "\n",
        "    pool_List=['max','maxavg']\n",
        "    random_pool=random.choice(pool_List)\n",
        "\n",
        "    neuType_list=['hidden','nohidden']\n",
        "    random_neuType=random.choice(neuType_list)\n",
        "    dropoutList=[0.5,0.75,1.0]\n",
        "\n",
        "    dropprob=random.choice(dropoutList)\n",
        "\n",
        "    learning_rate=logsampler(0.0005,0.05)\n",
        "\n",
        "    momentum_rate=sqrtsampler(0.95,0.99)\n",
        "\n",
        "    sigmaConv=logsampler(10**-7,10**-3)\n",
        "\n",
        "\n",
        "    sigmaNeu=logsampler(10**-5,10**-2)\n",
        "    beta1=logsampler(10**-15,10**-3)\n",
        "    beta2=logsampler(10**-10,10**-3)\n",
        "    beta3=logsampler(10**-10,10**-3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    model_auc=[[],[],[]]\n",
        "    for kk in range(3):\n",
        "        model = ConvNet(16,24,random_pool,random_neuType,'training',dropprob,learning_rate,momentum_rate,sigmaConv,sigmaNeu,beta1,beta2,beta3,reverse_complemet_mode=reverse_mode).to(device)\n",
        "        if random_neuType=='nohidden':\n",
        "            optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "\n",
        "        else:\n",
        "            optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias,model.wHidden,model.wHiddenBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "\n",
        "        train_loader=train_dataloader[kk]\n",
        "        valid_loader=valid_dataloader[kk]\n",
        "        learning_steps=0\n",
        "        while learning_steps<=20000:\n",
        "            model.mode='training'\n",
        "            auc=[]\n",
        "            for i, (data, target) in enumerate(train_loader):\n",
        "                data = data.to(device)\n",
        "                target = target.to(device)\n",
        "                if model.reverse_complemet_mode:\n",
        "                  target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "                  for i in range(target_2.shape[0]):\n",
        "                    target_2[i]=target[2*i]\n",
        "                  target=target_2.to(device)\n",
        "\n",
        "\n",
        "                # Forward pass\n",
        "                output = model(data)\n",
        "                if model.neuType=='nohidden':\n",
        "                    loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta3*model.wNeu.norm()\n",
        "\n",
        "                else:\n",
        "                    loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta2*model.wHidden.norm()+model.beta3*model.wNeu.norm()\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                learning_steps+=1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                if learning_steps% 4000==0:\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        model.mode='test'\n",
        "                        auc=[]\n",
        "                        for i, (data, target) in enumerate(valid_loader):\n",
        "                            data = data.to(device)\n",
        "                            target = target.to(device)\n",
        "                            if model.reverse_complemet_mode:\n",
        "                              target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "                              for i in range(target_2.shape[0]):\n",
        "                                target_2[i]=target[2*i]\n",
        "                              target=target_2.to(device)\n",
        "                            # Forward pass\n",
        "                            output = model(data)\n",
        "                            pred_sig=torch.sigmoid(output)\n",
        "                            pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "                            labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "\n",
        "                            auc.append(metrics.roc_auc_score(labels, pred))\n",
        "#                         print(np.mean(auc))\n",
        "                        model_auc[kk].append(np.mean(auc))\n",
        "                        print('AUC performance when training fold number ',kk+1, 'using ',learning_steps_list[len(model_auc[kk])-1],'learning steps = ',np.mean(auc))\n",
        "\n",
        "    print('                   ##########################################               ')\n",
        "    for n in range(5):\n",
        "        AUC=(model_auc[0][n]+model_auc[1][n]+model_auc[2][n])/3\n",
        "        #print(AUC)\n",
        "        if AUC>best_AUC:\n",
        "            best_AUC=AUC\n",
        "            best_learning_steps=learning_steps_list[n]\n",
        "            best_LearningRate=model.learning_rate\n",
        "            best_LearningMomentum=model.momentum_rate\n",
        "            best_neuType=model.neuType\n",
        "            best_poolType=model.poolType\n",
        "            best_sigmaConv=model.sigmaConv\n",
        "            best_dropprob=model.dropprob\n",
        "            best_sigmaNeu=model.sigmaNeu\n",
        "            best_beta1=model.beta1\n",
        "            best_beta2=model.beta2\n",
        "            best_beta3=model.beta3\n",
        "\n",
        "print('best_poolType=',best_poolType)\n",
        "print('best_neuType=',best_neuType)\n",
        "print('best_AUC=',best_AUC)\n",
        "print('best_learning_steps=',best_learning_steps)\n",
        "print('best_LearningRate=',best_LearningRate)\n",
        "print('best_LearningMomentum=',best_LearningMomentum)\n",
        "print('best_sigmaConv=',best_sigmaConv)\n",
        "print('best_dropprob=',best_dropprob)\n",
        "print('best_sigmaNeu=',best_sigmaNeu)\n",
        "print('best_beta1=',best_beta1)\n",
        "print('best_beta2=',best_beta2)\n",
        "print('best_beta3=',best_beta3)\n",
        "\n",
        "best_hyperparameters = {'best_poolType': best_poolType,'best_neuType':best_neuType,'best_learning_steps':best_learning_steps,'best_LearningRate':best_LearningRate,\n",
        "                        'best_LearningMomentum':best_LearningMomentum,'best_sigmaConv':best_sigmaConv,'best_dropprob':best_dropprob,\n",
        "                        'best_sigmaNeu':best_sigmaNeu,'best_beta1':best_beta1, 'best_beta2':best_beta2,'best_beta3':best_beta3}\n",
        "torch.save(best_hyperparameters, '/content/drive/My Drive/Deepbind/best_hyperpamarameters.pth')\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "AUC performance when training fold number  1 using  4000 learning steps =  0.836888345759789\n",
            "AUC performance when training fold number  1 using  8000 learning steps =  0.8276450994750457\n",
            "AUC performance when training fold number  1 using  12000 learning steps =  0.8267882050111585\n",
            "AUC performance when training fold number  1 using  16000 learning steps =  0.8210911347382837\n",
            "AUC performance when training fold number  1 using  20000 learning steps =  0.8181243976973017\n",
            "AUC performance when training fold number  2 using  4000 learning steps =  0.8035448683810104\n",
            "AUC performance when training fold number  2 using  8000 learning steps =  0.8004789495206939\n",
            "AUC performance when training fold number  2 using  12000 learning steps =  0.804169281928383\n",
            "AUC performance when training fold number  2 using  16000 learning steps =  0.8006114561143234\n",
            "AUC performance when training fold number  2 using  20000 learning steps =  0.8022784873326232\n",
            "AUC performance when training fold number  3 using  4000 learning steps =  0.7770489961996643\n",
            "AUC performance when training fold number  3 using  8000 learning steps =  0.7734366563671883\n",
            "AUC performance when training fold number  3 using  12000 learning steps =  0.7638568031470265\n",
            "AUC performance when training fold number  3 using  16000 learning steps =  0.7627968743864488\n",
            "AUC performance when training fold number  3 using  20000 learning steps =  0.7618964305742348\n",
            "                   ##########################################               \n",
            "AUC performance when training fold number  1 using  4000 learning steps =  0.7207520620942381\n",
            "AUC performance when training fold number  1 using  8000 learning steps =  0.8807692673463178\n",
            "AUC performance when training fold number  1 using  12000 learning steps =  0.8983152563273483\n",
            "AUC performance when training fold number  1 using  16000 learning steps =  0.8958348390900792\n",
            "AUC performance when training fold number  1 using  20000 learning steps =  0.891537726339014\n",
            "AUC performance when training fold number  2 using  4000 learning steps =  0.680704083929296\n",
            "AUC performance when training fold number  2 using  8000 learning steps =  0.7886295553104078\n",
            "AUC performance when training fold number  2 using  12000 learning steps =  0.7989695076333942\n",
            "AUC performance when training fold number  2 using  16000 learning steps =  0.7995105101820856\n",
            "AUC performance when training fold number  2 using  20000 learning steps =  0.796228871855346\n",
            "AUC performance when training fold number  3 using  4000 learning steps =  0.7016386532000373\n",
            "AUC performance when training fold number  3 using  8000 learning steps =  0.7278952672812812\n",
            "AUC performance when training fold number  3 using  12000 learning steps =  0.7370371216843696\n",
            "AUC performance when training fold number  3 using  16000 learning steps =  0.7484426346560678\n",
            "AUC performance when training fold number  3 using  20000 learning steps =  0.7484837234086937\n",
            "                   ##########################################               \n",
            "AUC performance when training fold number  1 using  4000 learning steps =  0.6672521286645364\n",
            "AUC performance when training fold number  1 using  8000 learning steps =  0.7456331469364983\n",
            "AUC performance when training fold number  1 using  12000 learning steps =  0.7771156278530128\n",
            "AUC performance when training fold number  1 using  16000 learning steps =  0.8830120127688172\n",
            "AUC performance when training fold number  1 using  20000 learning steps =  0.8977918869826537\n",
            "AUC performance when training fold number  2 using  4000 learning steps =  0.7669046554828566\n",
            "AUC performance when training fold number  2 using  8000 learning steps =  0.7973018820374315\n",
            "AUC performance when training fold number  2 using  12000 learning steps =  0.8002593071616961\n",
            "AUC performance when training fold number  2 using  16000 learning steps =  0.8046742255655306\n",
            "AUC performance when training fold number  2 using  20000 learning steps =  0.8072817603722865\n",
            "AUC performance when training fold number  3 using  4000 learning steps =  0.6209923606748081\n",
            "AUC performance when training fold number  3 using  8000 learning steps =  0.6890940633712426\n",
            "AUC performance when training fold number  3 using  12000 learning steps =  0.7362425633767646\n",
            "AUC performance when training fold number  3 using  16000 learning steps =  0.7665445405913159\n",
            "AUC performance when training fold number  3 using  20000 learning steps =  0.763403101255571\n",
            "                   ##########################################               \n",
            "AUC performance when training fold number  1 using  4000 learning steps =  0.8227946211199026\n",
            "AUC performance when training fold number  1 using  8000 learning steps =  0.8234672585083181\n",
            "AUC performance when training fold number  1 using  12000 learning steps =  0.8185859121398864\n",
            "AUC performance when training fold number  1 using  16000 learning steps =  0.8207141804245284\n",
            "AUC performance when training fold number  1 using  20000 learning steps =  0.8214420949355853\n",
            "AUC performance when training fold number  2 using  4000 learning steps =  0.8223360389404544\n",
            "AUC performance when training fold number  2 using  8000 learning steps =  0.8255677891686956\n",
            "AUC performance when training fold number  2 using  12000 learning steps =  0.819935109809292\n",
            "AUC performance when training fold number  2 using  16000 learning steps =  0.821667126318726\n",
            "AUC performance when training fold number  2 using  20000 learning steps =  0.8206594976795496\n",
            "AUC performance when training fold number  3 using  4000 learning steps =  0.7873474520141657\n",
            "AUC performance when training fold number  3 using  8000 learning steps =  0.7888236176999686\n",
            "AUC performance when training fold number  3 using  12000 learning steps =  0.7895715173610429\n",
            "AUC performance when training fold number  3 using  16000 learning steps =  0.7855154458430683\n",
            "AUC performance when training fold number  3 using  20000 learning steps =  0.7854163765081088\n",
            "                   ##########################################               \n",
            "AUC performance when training fold number  1 using  4000 learning steps =  0.7219179933176101\n",
            "AUC performance when training fold number  1 using  8000 learning steps =  0.8830640604394907\n",
            "AUC performance when training fold number  1 using  12000 learning steps =  0.8866538439592209\n",
            "AUC performance when training fold number  1 using  16000 learning steps =  0.8815902019616049\n",
            "AUC performance when training fold number  1 using  20000 learning steps =  0.8830569080949483\n",
            "AUC performance when training fold number  2 using  4000 learning steps =  0.7611724773026983\n",
            "AUC performance when training fold number  2 using  8000 learning steps =  0.8095922054105802\n",
            "AUC performance when training fold number  2 using  12000 learning steps =  0.8078193155305337\n",
            "AUC performance when training fold number  2 using  16000 learning steps =  0.8043734110303815\n",
            "AUC performance when training fold number  2 using  20000 learning steps =  0.8066419326308581\n",
            "AUC performance when training fold number  3 using  4000 learning steps =  0.7308862907213889\n",
            "AUC performance when training fold number  3 using  8000 learning steps =  0.7720070055268687\n",
            "AUC performance when training fold number  3 using  12000 learning steps =  0.7713661801257289\n",
            "AUC performance when training fold number  3 using  16000 learning steps =  0.7682203596514048\n",
            "AUC performance when training fold number  3 using  20000 learning steps =  0.765653300046139\n",
            "                   ##########################################               \n",
            "best_poolType= max\n",
            "best_neuType= nohidden\n",
            "best_AUC= 0.8228255828701704\n",
            "best_learning_steps= 20000\n",
            "best_LearningRate= 0.00149686214639654\n",
            "best_LearningMomentum= 0.9684532251520251\n",
            "best_sigmaConv= 1.7652801911120897e-06\n",
            "best_dropprob= 0.5\n",
            "best_sigmaNeu= 0.005078164449650418\n",
            "best_beta1= 4.952019110810548e-09\n",
            "best_beta2= 2.0171531663711034e-06\n",
            "best_beta3= 1.3761925228468403e-06\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "rwZUA6cmRtlN"
      },
      "cell_type": "code",
      "source": [
        "# input of shape(batch_size,inp_chan,iW)\n",
        "class ConvNet_test(nn.Module):\n",
        "    def __init__(self,nummotif,motiflen,poolType,neuType,mode,learning_steps,learning_rate,learning_Momentum,sigmaConv,dropprob,sigmaNeu,beta1,beta2,beta3,reverse_complemet_mode):\n",
        "        super(ConvNet_test, self).__init__()\n",
        "        self.poolType=poolType\n",
        "        self.neuType=neuType\n",
        "        self.mode=mode\n",
        "        self.learning_rate=learning_rate\n",
        "        self.reverse_complemet_mode=reverse_complemet_mode\n",
        "        self.momentum_rate=learning_Momentum\n",
        "        self.sigmaConv=sigmaConv\n",
        "        self.wConv=torch.randn(nummotif,4,motiflen).to(device)\n",
        "        torch.nn.init.normal_(self.wConv,mean=0,std=self.sigmaConv)\n",
        "        self.wConv.requires_grad=True\n",
        "        self.wRect=torch.randn(nummotif).to(device)\n",
        "        torch.nn.init.normal_(self.wRect)\n",
        "        self.wRect=-self.wRect\n",
        "        self.wRect.requires_grad=True\n",
        "        self.dropprob=dropprob\n",
        "        self.sigmaNeu=sigmaNeu\n",
        "        self.wHidden=torch.randn(2*nummotif,32).to(device)\n",
        "        self.wHiddenBias=torch.randn(32).to(device)\n",
        "        if neuType=='nohidden':\n",
        "\n",
        "            if poolType=='maxavg':\n",
        "                self.wNeu=torch.randn(2*nummotif,1).to(device)\n",
        "            else:\n",
        "                self.wNeu=torch.randn(nummotif,1).to(device)\n",
        "            self.wNeuBias=torch.randn(1).to(device)\n",
        "            torch.nn.init.normal_(self.wNeu,mean=0,std=self.sigmaNeu)\n",
        "            torch.nn.init.normal_(self.wNeuBias,mean=0,std=self.sigmaNeu)\n",
        "\n",
        "        else:\n",
        "            if poolType=='maxavg':\n",
        "                self.wHidden=torch.randn(2*nummotif,32).to(device)\n",
        "            else:\n",
        "\n",
        "                self.wHidden=torch.randn(nummotif,32).to(device)\n",
        "            self.wNeu=torch.randn(32,1).to(device)\n",
        "            self.wNeuBias=torch.randn(1).to(device)\n",
        "            self.wHiddenBias=torch.randn(32).to(device)\n",
        "            torch.nn.init.normal_(self.wNeu,mean=0,std=self.sigmaNeu)\n",
        "            torch.nn.init.normal_(self.wNeuBias,mean=0,std=self.sigmaNeu)\n",
        "            torch.nn.init.normal_(self.wHidden,mean=0,std=0.3)\n",
        "            torch.nn.init.normal_(self.wHiddenBias,mean=0,std=0.3)\n",
        "\n",
        "\n",
        "            self.wHidden.requires_grad=True\n",
        "            self.wHiddenBias.requires_grad=True\n",
        "            #wHiddenBias=tf.Variable(tf.truncated_normal([32,1],mean=0,stddev=sigmaNeu)) #hidden bias for everything\n",
        "\n",
        "        self.wNeu.requires_grad=True\n",
        "        self.wNeuBias.requires_grad=True\n",
        "\n",
        "\n",
        "        self.beta1=beta1\n",
        "        self.beta2=beta2\n",
        "        self.beta3=beta3\n",
        "\n",
        "\n",
        "\n",
        "    def divide_two_tensors(self,x):\n",
        "        l=torch.unbind(x)\n",
        "\n",
        "        list1=[l[2*i] for i in range(int(x.shape[0]/2))]\n",
        "        list2=[l[2*i+1] for i in range(int(x.shape[0]/2))]\n",
        "        x1=torch.stack(list1,0)\n",
        "        x2=torch.stack(list2,0)\n",
        "        return x1,x2\n",
        "    def forward_pass(self,x,mask=None,use_mask=False):\n",
        "\n",
        "        conv=F.conv1d(x, self.wConv, bias=self.wRect, stride=1, padding=0)\n",
        "        rect=conv.clamp(min=0)\n",
        "        maxPool, _ = torch.max(rect, dim=2)\n",
        "        if self.poolType=='maxavg':\n",
        "            avgPool= torch.mean(rect, dim=2)\n",
        "            pool=torch.cat((maxPool, avgPool), 1)\n",
        "        else:\n",
        "            pool=maxPool\n",
        "        if(self.neuType=='nohidden'):\n",
        "            if self.mode=='training':\n",
        "                if  not use_mask:\n",
        "                    mask=bernoulli.rvs(self.dropprob, size=len(pool[0]))\n",
        "                    mask=torch.from_numpy(mask).float().to(device)\n",
        "                pooldrop=pool*mask\n",
        "                out=pooldrop @ self.wNeu\n",
        "                out.add_(self.wNeuBias)\n",
        "            else:\n",
        "                out=self.dropprob*(pool @ self.wNeu)\n",
        "                out.add_(self.wNeuBias)\n",
        "        else:\n",
        "            hid=pool @ self.wHidden\n",
        "            hid.add_(self.wHiddenBias)\n",
        "            hid=hid.clamp(min=0)\n",
        "            if self.mode=='training':\n",
        "                if  not use_mask:\n",
        "                    mask=bernoulli.rvs(self.dropprob, size=len(hid[0]))\n",
        "                    mask=torch.from_numpy(mask).float().to(device)\n",
        "                hiddrop=hid*mask\n",
        "                out=self.dropprob*(hid @ self.wNeu)\n",
        "                out.add_(self.wNeuBias)\n",
        "            else:\n",
        "                out=self.dropprob*(hid @ self.wNeu)\n",
        "                out.add_(self.wNeuBias)\n",
        "        return out,mask\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if not  self.reverse_complemet_mode:\n",
        "            out,_=self.forward_pass(x)\n",
        "        else:\n",
        "\n",
        "            x1,x2=self.divide_two_tensors(x)\n",
        "            out1,mask=self.forward_pass(x1)\n",
        "            out2,_=self.forward_pass(x2,mask,True)\n",
        "            out=torch.max(out1, out2)\n",
        "\n",
        "        return out\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fkrEJTXuz8GW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3b09a1a-b4e9-4c92-82c8-c0a958d7add0"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "learning_steps_list=[4000,8000,12000,16000,20000]\n",
        "best_AUC=0\n",
        "\n",
        "best_hyperparameters = torch.load('/content/drive/My Drive/Deepbind/best_hyperpamarameters.pth')\n",
        "\n",
        "best_poolType=best_hyperparameters['best_poolType']\n",
        "best_neuType=best_hyperparameters['best_neuType']\n",
        "best_learning_steps=best_hyperparameters['best_learning_steps']\n",
        "best_LearningRate=best_hyperparameters['best_LearningRate']\n",
        "best_dropprob=best_hyperparameters['best_dropprob']\n",
        "best_LearningMomentum=best_hyperparameters['best_LearningMomentum']\n",
        "best_sigmaConv=best_hyperparameters['best_sigmaConv']\n",
        "best_sigmaNeu=best_hyperparameters['best_sigmaNeu']\n",
        "best_beta1=best_hyperparameters['best_beta1']\n",
        "best_beta2=best_hyperparameters['best_beta2']\n",
        "best_beta3=best_hyperparameters['best_beta3']\n",
        "\n",
        "\n",
        "for number_models in range(6):\n",
        "\n",
        "  model = ConvNet_test(16,24,best_poolType,best_neuType,'training',best_learning_steps,best_LearningRate,best_LearningMomentum,best_sigmaConv,best_dropprob,best_sigmaNeu,best_beta1,best_beta2,best_beta3,reverse_complemet_mode=False).to(device)\n",
        "\n",
        "  if model.neuType=='nohidden':\n",
        "      optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "\n",
        "  else:\n",
        "      optimizer = torch.optim.SGD([model.wConv,model.wRect,model.wNeu,model.wNeuBias,model.wHidden,model.wHiddenBias], lr=model.learning_rate,momentum=model.momentum_rate,nesterov=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  train_loader=alldataset_loader\n",
        "  valid_loader=alldataset_loader\n",
        "  learning_steps=0\n",
        "  while learning_steps<=best_learning_steps:\n",
        "\n",
        "      for i, (data, target) in enumerate(train_loader):\n",
        "          data = data.to(device)\n",
        "          target = target.to(device)\n",
        "          if model.reverse_complemet_mode:\n",
        "              target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "              for i in range(target_2.shape[0]):\n",
        "                target_2[i]=target[2*i]\n",
        "              target=target_2.to(device)\n",
        "            # Forward pass\n",
        "          output = model(data)\n",
        "\n",
        "          if model.neuType=='nohidden':\n",
        "              loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta3*model.wNeu.norm()\n",
        "\n",
        "          else:\n",
        "              loss = F.binary_cross_entropy(torch.sigmoid(output),target)+model.beta1*model.wConv.norm()+model.beta2*model.wHidden.norm()+model.beta3*model.wNeu.norm()\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          learning_steps+=1\n",
        "\n",
        "  with torch.no_grad():\n",
        "      model.mode='test'\n",
        "      auc=[]\n",
        "      for i, (data, target) in enumerate(valid_loader):\n",
        "          data = data.to(device)\n",
        "          target = target.to(device)\n",
        "          if model.reverse_complemet_mode:\n",
        "              target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "              for i in range(target_2.shape[0]):\n",
        "                target_2[i]=target[2*i]\n",
        "              target=target_2.to(device)\n",
        "          # Forward pass\n",
        "          output = model(data)\n",
        "          pred_sig=torch.sigmoid(output)\n",
        "          pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "          labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "\n",
        "          auc.append(metrics.roc_auc_score(labels, pred))\n",
        "  #\n",
        "      AUC_training=np.mean(auc)\n",
        "      print('AUC for model ',number_models,' = ',AUC_training)\n",
        "      if AUC_training>best_AUC:\n",
        "          state = {'conv': model.wConv,'rect':model.wRect,'wHidden':model.wHidden,'wHiddenBias':model.wHiddenBias,'wNeu':model.wNeu,'wNeuBias':model.wNeuBias }\n",
        "          torch.save(state, '/content/drive/My Drive/Deepbind/MyModel_2.pth')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "AUC for model  0  =  0.8454555687251315\n",
            "AUC for model  1  =  0.8697160836622384\n",
            "AUC for model  2  =  0.8560260336445898\n",
            "AUC for model  3  =  0.7958983748275253\n",
            "AUC for model  4  =  0.8616857341403542\n",
            "AUC for model  5  =  0.8715530138942369\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "JetF0ajS4faT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96a4914b-cfbc-4fdd-d7d7-5bcd503b2d88"
      },
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('/content/drive/My Drive/Deepbind/MyModel_2.pth')\n",
        "model = ConvNet_test(16,24,best_poolType,best_neuType,'test',best_learning_steps,best_LearningRate,best_LearningMomentum,best_sigmaConv,best_dropprob,best_sigmaNeu,best_beta1,best_beta2,best_beta3,reverse_complemet_mode=reverse_mode).to(device)\n",
        "model.wConv=checkpoint['conv']\n",
        "model.wRect=checkpoint['rect']\n",
        "model.wHidden=checkpoint['wHidden']\n",
        "model.wHiddenBias=checkpoint['wHiddenBias']\n",
        "model.wNeu=checkpoint['wNeu']\n",
        "model.wNeuBias=checkpoint['wNeuBias']\n",
        "\n",
        "with torch.no_grad():\n",
        "      model.mode='test'\n",
        "      auc=[]\n",
        "\n",
        "      for i, (data, target) in enumerate(valid_loader):\n",
        "          data = data.to(device)\n",
        "          target = target.to(device)\n",
        "          if model.reverse_complemet_mode:\n",
        "              target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "              for i in range(target_2.shape[0]):\n",
        "                target_2[i]=target[2*i]\n",
        "              target=target_2.to(device)\n",
        "          # Forward pass\n",
        "          output = model(data)\n",
        "          pred_sig=torch.sigmoid(output)\n",
        "          pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "          labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "\n",
        "          auc.append(metrics.roc_auc_score(labels, pred))\n",
        "  #\n",
        "      AUC_training=np.mean(auc)\n",
        "      print(AUC_training)\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8715530138942369\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "AObJY0ZjjNLW"
      },
      "cell_type": "code",
      "source": [
        "class Chip_test():\n",
        "    def __init__(self,filename,motiflen=24,reverse_complemet_mode=reverse_mode):\n",
        "        self.file = filename\n",
        "        self.motiflen = motiflen\n",
        "        self.reverse_complemet_mode=reverse_complemet_mode\n",
        "\n",
        "    def openFile(self):\n",
        "        test_dataset=[]\n",
        "        with gzip.open(self.file, 'rt') as data:\n",
        "            next(data)\n",
        "            reader = csv.reader(data,delimiter='\\t')\n",
        "            if not self.reverse_complemet_mode:\n",
        "              for row in reader:\n",
        "                      test_dataset.append([seqtopad(row[2],self.motiflen),[int(row[3])]])\n",
        "            else:\n",
        "              for row in reader:\n",
        "                      test_dataset.append([seqtopad(row[2],self.motiflen),[int(row[3])]])\n",
        "                      test_dataset.append([seqtopad(reverse_complement(row[2]),self.motiflen),[int(row[3])]])\n",
        "\n",
        "        return test_dataset\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZObdD8Yaj8w1"
      },
      "cell_type": "code",
      "source": [
        "chipseq_test=Chip_test('/content/drive/My Drive/Deepbind/data/encode/ELK1_GM12878_ELK1_(1277-1)_Stanford_B.seq.gz')\n",
        "test_data=chipseq_test.openFile()\n",
        "test_dataset=chipseq_dataset(test_data)\n",
        "batchSize=test_dataset.__len__()\n",
        "test_loader = DataLoader(dataset=test_dataset,batch_size=batchSize,shuffle=False)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C4oqk1HnfQQw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57189980-e52b-41ea-e93f-ee98db1a2fe4"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "with torch.no_grad():\n",
        "      model.mode='test'\n",
        "      auc=[]\n",
        "\n",
        "      for i, (data, target) in enumerate(test_loader):\n",
        "          data = data.to(device)\n",
        "          target = target.to(device)\n",
        "          if model.reverse_complemet_mode:\n",
        "              target_2=torch.randn(int(target.shape[0]/2),1)\n",
        "              for i in range(target_2.shape[0]):\n",
        "                target_2[i]=target[2*i]\n",
        "              target=target_2.to(device)\n",
        "          # Forward pass\n",
        "          output = model(data)\n",
        "          pred_sig=torch.sigmoid(output)\n",
        "          pred=pred_sig.cpu().detach().numpy().reshape(output.shape[0])\n",
        "          labels=target.cpu().numpy().reshape(output.shape[0])\n",
        "\n",
        "          auc.append(metrics.roc_auc_score(labels, pred))\n",
        "  #\n",
        "      AUC_training=np.mean(auc)\n",
        "      print('AUC on test data = ',AUC_training)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC on test data =  0.929972\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "AtHbPeAohR6m"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}